--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 50820 on
node mb-sab014.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab014.cism.ucl.ac.be:50819] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab014.cism.ucl.ac.be:50819] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
forrtl: error (78): process killed (SIGTERM)
Image              PC                Routine            Line        Source             
ld-linux-x86-64.s  000000381980960F  Unknown               Unknown  Unknown
ld-linux-x86-64.s  0000003819809EA5  Unknown               Unknown  Unknown
ld-linux-x86-64.s  000000381980A26A  Unknown               Unknown  Unknown
ld-linux-x86-64.s  000000381980E420  Unknown               Unknown  Unknown
ld-linux-x86-64.s  0000003819814C55  Unknown               Unknown  Unknown
libmpi.so.1        00007F667E12F2A0  Unknown               Unknown  Unknown
libmpi.so.1        00007F667E12E589  Unknown               Unknown  Unknown
libmpi.so.1        00007F667DFF69E7  Unknown               Unknown  Unknown
libmpi_f77.so.1    00007F667E5BB78A  Unknown               Unknown  Unknown
pw.x               0000000000C8339C  mp_mp_mp_abort_           167  mp.f90
pw.x               0000000000C5F30C  errore_                   109  error_handler.f90
pw.x               00000000009261FF  read_input_mp_rea          53  read_input.f90
pw.x               000000000046B164  MAIN__                     76  pwscf.f90
pw.x               000000000046AFEC  Unknown               Unknown  Unknown
libc.so.6          0000003819C1ED1D  Unknown               Unknown  Unknown
pw.x               000000000046AEE9  Unknown               Unknown  Unknown
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 51418 on
node mb-sab014.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab014.cism.ucl.ac.be:51417] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab014.cism.ucl.ac.be:51417] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 1 with PID 51971 on
node mb-sab014.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab014.cism.ucl.ac.be:51969] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab014.cism.ucl.ac.be:51969] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 52596 on
node mb-sab014.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab014.cism.ucl.ac.be:52595] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab014.cism.ucl.ac.be:52595] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--
