--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106643 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106642] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106642] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106647 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106646] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106646] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
forrtl: error (78): process killed (SIGTERM)
Image              PC                Routine            Line        Source             
libc.so.6          000000316D0E3757  Unknown               Unknown  Unknown
pw.x               0000000000F09DE9  Unknown               Unknown  Unknown
pw.x               0000000000F3F409  Unknown               Unknown  Unknown
pw.x               0000000000F3E19A  Unknown               Unknown  Unknown
pw.x               0000000000C5F1BF  errore_                    98  error_handler.f90
pw.x               0000000000934025  read_pseudo_mod_m         147  read_pseudo.f90
pw.x               0000000000523618  iosys_                   1585  input.f90
pw.x               00000000005DA45D  run_pwscf_                 74  run_pwscf.f90
pw.x               000000000046B16F  MAIN__                     77  pwscf.f90
pw.x               000000000046AFEC  Unknown               Unknown  Unknown
libc.so.6          000000316D01ED1D  Unknown               Unknown  Unknown
pw.x               000000000046AEE9  Unknown               Unknown  Unknown
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106651 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 1 with PID 106656 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106654] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106654] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106659 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106658] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106658] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
forrtl: error (78): process killed (SIGTERM)
Image              PC                Routine            Line        Source             
libpthread.so.0    000000316D40E870  Unknown               Unknown  Unknown
pw.x               0000000000EE71F1  Unknown               Unknown  Unknown
pw.x               0000000000EE6A32  Unknown               Unknown  Unknown
pw.x               0000000000C5F2FD  errore_                   105  error_handler.f90
pw.x               0000000000934025  read_pseudo_mod_m         147  read_pseudo.f90
pw.x               0000000000523618  iosys_                   1585  input.f90
pw.x               00000000005DA45D  run_pwscf_                 74  run_pwscf.f90
pw.x               000000000046B16F  MAIN__                     77  pwscf.f90
pw.x               000000000046AFEC  Unknown               Unknown  Unknown
libc.so.6          000000316D01ED1D  Unknown               Unknown  Unknown
pw.x               000000000046AEE9  Unknown               Unknown  Unknown
forrtl: severe (28): CLOSE error, unit 99, file "Unknown"
Image              PC                Routine            Line        Source             
pw.x               0000000000FA392E  Unknown               Unknown  Unknown
pw.x               0000000000FA23C6  Unknown               Unknown  Unknown
pw.x               0000000000F55E92  Unknown               Unknown  Unknown
pw.x               0000000000EEFE9B  Unknown               Unknown  Unknown
pw.x               0000000000EF3421  Unknown               Unknown  Unknown
pw.x               0000000000EF6E1A  Unknown               Unknown  Unknown
libpthread.so.0    000000316D40F7E0  Unknown               Unknown  Unknown
libpthread.so.0    000000316D40E870  Unknown               Unknown  Unknown
pw.x               0000000000EE71F1  Unknown               Unknown  Unknown
pw.x               0000000000EE6A32  Unknown               Unknown  Unknown
pw.x               0000000000C5F2FD  errore_                   105  error_handler.f90
pw.x               0000000000934025  read_pseudo_mod_m         147  read_pseudo.f90
pw.x               0000000000523618  iosys_                   1585  input.f90
pw.x               00000000005DA45D  run_pwscf_                 74  run_pwscf.f90
pw.x               000000000046B16F  MAIN__                     77  pwscf.f90
pw.x               000000000046AFEC  Unknown               Unknown  Unknown
libc.so.6          000000316D01ED1D  Unknown               Unknown  Unknown
pw.x               000000000046AEE9  Unknown               Unknown  Unknown
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106663 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106667 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106666] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106666] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106671 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106670] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106670] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 1 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 1 with PID 106676 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106674] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106674] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106679 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106678] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106678] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106683 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106682] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106682] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
forrtl: error (78): process killed (SIGTERM)
Image              PC                Routine            Line        Source             
libc.so.6          000000316D0DB580  Unknown               Unknown  Unknown
libc.so.6          000000316D07295F  Unknown               Unknown  Unknown
libc.so.6          000000316D066D96  Unknown               Unknown  Unknown
libmpi.so.1        00007FE30CED0C35  Unknown               Unknown  Unknown
libmpi.so.1        00007FE30CE12459  Unknown               Unknown  Unknown
libmpi.so.1        00007FE30CCF8FAA  Unknown               Unknown  Unknown
libmpi_f77.so.1    00007FE30D2B178A  Unknown               Unknown  Unknown
pw.x               0000000000C8339C  mp_mp_mp_abort_           167  mp.f90
pw.x               0000000000C5F30C  errore_                   109  error_handler.f90
pw.x               0000000000934025  read_pseudo_mod_m         147  read_pseudo.f90
pw.x               0000000000523618  iosys_                   1585  input.f90
pw.x               00000000005DA45D  run_pwscf_                 74  run_pwscf.f90
pw.x               000000000046B16F  MAIN__                     77  pwscf.f90
pw.x               000000000046AFEC  Unknown               Unknown  Unknown
libc.so.6          000000316D01ED1D  Unknown               Unknown  Unknown
pw.x               000000000046AEE9  Unknown               Unknown  Unknown
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106687 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
forrtl: error (78): process killed (SIGTERM)
Image              PC                Routine            Line        Source             
libc.so.6          000000316D0DB580  Unknown               Unknown  Unknown
libc.so.6          000000316D07295F  Unknown               Unknown  Unknown
libc.so.6          000000316D066D96  Unknown               Unknown  Unknown
libmpi.so.1        00007F26AFC6FC35  Unknown               Unknown  Unknown
libmpi.so.1        00007F26AFBB1459  Unknown               Unknown  Unknown
libmpi.so.1        00007F26AFA97FAA  Unknown               Unknown  Unknown
libmpi_f77.so.1    00007F26B005078A  Unknown               Unknown  Unknown
pw.x               0000000000C8339C  mp_mp_mp_abort_           167  mp.f90
pw.x               0000000000C5F30C  errore_                   109  error_handler.f90
pw.x               0000000000934025  read_pseudo_mod_m         147  read_pseudo.f90
pw.x               0000000000523618  iosys_                   1585  input.f90
pw.x               00000000005DA45D  run_pwscf_                 74  run_pwscf.f90
pw.x               000000000046B16F  MAIN__                     77  pwscf.f90
pw.x               000000000046AFEC  Unknown               Unknown  Unknown
libc.so.6          000000316D01ED1D  Unknown               Unknown  Unknown
pw.x               000000000046AEE9  Unknown               Unknown  Unknown
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106691 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106695 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106694] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106694] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD 
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun has exited due to process rank 0 with PID 106699 on
node mb-sab102.cism.ucl.ac.be exiting improperly. There are two reasons this could occur:

1. this process did not call "init" before exiting, but others in
the job did. This can cause a job to hang indefinitely while it waits
for all processes to call "init". By rule, if one process calls "init",
then ALL processes must call "init" prior to termination.

2. this process called "init", but exited without calling "finalize".
By rule, all processes that call "init" MUST call "finalize" prior to
exiting or it will be considered an "abnormal termination"

This may have caused other processes in the application to be
terminated by signals sent by mpirun (as reported here).
--------------------------------------------------------------------------
[mb-sab102.cism.ucl.ac.be:106698] 1 more process has sent help message help-mpi-api.txt / mpi-abort
[mb-sab102.cism.ucl.ac.be:106698] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
--
